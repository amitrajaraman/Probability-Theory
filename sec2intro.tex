\section{Introduction to Probability}

\subsection{Basic Definitions}

\begin{definition}[Probability Measure]
    Let $\mathcal{A}$ be a $\sigma$-algebra and $\mu$ be a measure on $\mathcal{A}$. $\mu$ is called a \textit{probability measure} if $\mu(\Omega)=1$.
\end{definition}

Let $\Omega$ be a countable non-empty set and $\mathcal{A}=2^\Omega$. Further let $(p_\omega)_{\omega\in\Omega}$ be non-negative numbers. The map given by $A\mapsto\mu(A)=\sum_{\omega\in A}p_\omega$ defines a $\sigma$-finite measure on $2^\Omega$. $p=(p_\omega)_{\omega\in\Omega}$ is called the \textit{weight function} of $\mu$. $p_\omega$ is called the \textit{weight of $\mu$ at point $\omega$}.

In the case where $\sum_{\omega\in\Omega}p_\omega=1$, $\mu$ is a probability measure. Then the vector $(p_\omega)_{\omega\in\Omega}$ is called a \textit{probability vector}. 

\begin{definition}[Probability Distribution Function]
    A right continuous monotonically increasing function $F:\mathbb{R}\to[0,1]$ such that $\lim_{x\to-\infty}F(x)=0$ and $\lim_{x\to\infty}F(x)=1$ is called a \textit{(proper) probability distribution function}, often abbreviated as \textit{p.d.f.} If we instead have $\lim_{x\to\infty}F(x)\leq 1$, $F$ is called a \textit{(possibly) defective p.d.f.} If $\mu$ is a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$, then the function $F_\mu$ given by $x\mapsto \mu((\infty,x])$ is called the \textit{distribution function} of $\mu$.
\end{definition}

Note that a probability measure is uniquely determined by its distribution function.

\begin{definition}[Probability Space]
    Let $(\Omega,\mathcal{A},\mu)$ be a measure space. If in addition $\mu(\Omega)=1$, then $(\Omega,\mathcal{A},\mu)$ is called a \textit{probability space}.
\end{definition}

In the above definition, $\Omega$ is called the \textit{sample space}, $\mathcal{A}$ is called the \textit{event space} (and its elements are called \textit{events}, and $\mu$ is called the \textit{probability function}.

\vspace{2mm}
Let $\Omega$ be a finite nonempty set. Let $\mathcal{A}=2^\Omega$ and consider the function $\mu:\mathcal{A}\to[0,1]$ given by
$$\mu(A)=\frac{|A|}{|\Omega|}\text{ for each $A\subseteq\Omega$.}$$
This defines a probability measure on $\mathcal{A}$. This function $\mu$ is called the \textit{uniform distribution on $\Omega$} and is denoted $\mathcal{U}_\Omega$. The resulting probability space $(\Omega,\mathcal{A},\mathcal{U}_\Omega)$ is called a \textit{Laplace space}.

\vspace{2mm}
Another example is as follows. Let $\omega\in\Omega$ and $\delta_\omega(A)=\indic(\{\omega\})$. Then $\delta_\omega$ is a probability measure on any $\sigma$-algebra $\mathcal{A}\subseteq2^\Omega$. $\delta_\omega$ is called the \textit{Dirac measure} for the point $\omega$.

The Dirac measure is useful in constructing discrete probability distributions.

\vspace{2mm}
Consider the example of a coin toss. The sample space $\Omega$ has two elements, $\text{H}$ (for heads) and $\text{T}$ (for tails). The event space $\mathcal{A}$ then has four elements $\emptyset$, $\{H\}$, $\{T\}$, and $\{H,T\}$. Each of these events have associated probabilities $0,\frac{1}{2},\frac{1}{2}$, and $1$ respectively. Note that $\{H,T\}$ represents the event that either a heads or a tails occurs.`

\begin{definition}[Random Variable]
    Let $(\Omega,\mathcal{A},\textbf{P})$ be a probability space, $(\Omega',\mathcal{A}')$ a measurable space, and $X:\Omega\to\Omega'$ be measurable. Then
    \begin{enumerate}[(i)]
        \item $X$ is called a \textit{random variable} with values in $(\Omega',\mathcal{A}')$. If $(\Omega',\mathcal{A}')=(\mathbb{R},\mathcal{B}(\mathbb{R}))$, then $X$ is called a \textit{real random variable}.
        
        \item For $A'\in\mathcal{A}'$, we often denote
        $$\textbf{P}[X^{-1}(A')]\text{ as }\textbf{P}[X\in A']\text{ and } X^{-1}(A')\text{ as }\{X\in A'\}.$$
        In particular, we let $\{X\geq 0\}=X^{-1}([0,\infty))$ and define $\{X\leq b\}$ and other terms similarly.
    \end{enumerate}
\end{definition}

As we shall primarily deal with real random variables in our study of probability, we often drop the ``real" and refer to them as just random variables.

\begin{definition}
    Let $X$ be a random variable with underlying probability space $(\Omega,\mathcal{A},\textbf{P})$.
    \begin{enumerate}[(i)]
        \item The probability measure $\textbf{P}_X=\textbf{P}\circ X^{-1}$ is called the \textit{distribution} of $X$.
        \item For a real random variable $X$, the map $F_X$ given by $x\mapsto\textbf{P}[X\leq x]$ is called the \textit{distribution function} of $P_X$ (or $X$). If $\mu=\textbf{P}_X$, we write $X\sim\mu$ and say that $X$ has distribution $\mu$.
        \item A family $(X_i)_{i\in I}$ of random variables is called \textit{identically distributed} if $\textbf{P}_{X_i}=\textbf{P}_{X_j}$ for all $i,j\in I$. We write $X\iddistrib Y$ if $\textbf{P}_X=\textbf{P}_Y$ ($\mathcal{D}$ for \textit{distribution}).
    \end{enumerate}
\end{definition}

\begin{theorem}
    For any p.d.f. $F$, there exists a real random variable $X$ with $F_X=F$.
\end{theorem}

\begin{proof}
    We shall explicitly construct a probability space $(\Omega,\mathcal{A},\textbf{P})$ and random variable $X:\Omega\to\mathbb{R}$ such that $F_X=F$.
    
    \vspace{1mm}
    One choice that might come to mind is to take $(\Omega,\mathcal{A}) = (\mathbb{R},\mathcal{B}(\mathbb{R}))$, $X:\mathbb{R}\to\mathbb{R}$ as the identity function, and \textbf{$P$} the Lebesgue-Stieltjes measure with distribution function $F$.
    
    \vspace{1.5mm}
    While this choice of ours works, let us attempt to construct another more ``standard" choice that is perhaps more enlightening. Let $\Omega=(0,1),\mathcal{A}=\left.\mathcal{B}(\Omega)\right|_\Omega$ and $\textbf{P}$ be the Lebesgue measure on $(\Omega,\mathcal{A})$. This is standard in the sense that given any $F$, we construct a random variable over the same probability space. Define the left continuous inverse of $F$ as
    $$F^{-1}(t)=\inf\{x\in\mathbb{R}:F(x)\geq t\}\text{ for }t\in (0,1).$$
    Note that $F^{-1}(t)\leq x$ if and only if $F(x)\geq t$.
    In particular,
    $$\{t:F^{-1}(t)\leq x\}=(0,F(x)]\cap(0,1)$$
    and so $F^{-1}:(\Omega,\mathcal{A})\to(\mathbb{R},\mathcal{B}(\mathbb{R}))$ is measurable. Thus
    $$\textbf{P}\left[\{t:F^{-1}(t)\leq x\}\right]=F(x).$$
    This implies that $F^{-1}$ is the random variable we wish to construct.
\end{proof}

Note that the above implies that there is a bijection between probability distribution functions and distribution functions corresponding to random variables.

\begin{definition}
    If a distribution $F:\mathbb{R}^n\to[0,1]$ is of the form
    $$F(x)=\int_{-\infty}^{x_1}\d{t_1}\int_{-\infty}^{x_2}\d{t_2}\cdots\int_{-\infty}^{x_n}\d{t_n}\, f(t_1,t_2,\ldots,t_n)\text{ for }(x_1,x_2,\ldots,x_n)\in\mathbb{R}^n$$
    for some integrable function $f:\mathbb{R}^n\to[0,\infty)$, then $f$ is called the \textit{density of the distribution}.
\end{definition}

\subsection{Important Examples of Random Variables}

We now give several important examples of random variables that we shall encounter several times in our study of probability.

\begin{enumerate}
    \item \textit{Bernoulli Distribution.}
    
    Let $p\in[0,1]$ and $\textbf{P}[X=1]=p$, $P[X=0]=1-p$. Then $\textbf{P}_X$ is called the \textit{Bernoulli distribution with parameter $p$} and is denoted $\Ber_p$. More formally,
    $$\Ber_p=(1-p)\delta_0 + p\delta_1.$$
    Its distribution function is
    $$
    F_X(x) = 
    \begin{cases}
    0, &x<0 \\
    1-p, &x\in[0,1) \\
    1, &x\geq 1
    \end{cases}
    $$
    
    Note that the above can be likened to the outcome of a weighted coin, with heads and tails corresponding to $0$ and $1$.
    
    \vspace{2mm}
    The distribution $\textbf{P}_Y$ of $Y=2X-1$ is called the \textit{Rademacher distribution with parameter $p$}. More formally,
    $$\Rad_p = (1-p)\delta_{-1}+p\delta_1.$$
    $\Rad_{1/2}$ is simply called the Rademacher distribution.
    
    \item \textit{Binomial Distribution.}
    
    Let $p\in[0,1]$ and $n\in\mathbb{N}$. Let $X:\Omega\to\{0,1,2,\ldots,n\}$ be such that for each valid $k$,
    $$\textbf{P}[X=k]=\binom{n}{k}p^k(1-p)^{n-k}.$$
    Then $\textbf{P}_X$ is called the \textit{binomial distribution with parameters $n$ and $p$} and is denoted $b_{n,p}$. More formally,
    $$b_{n,p}=\sum_{k=0}^n \binom{n}{k}p^k(1-p)^{n-k}\delta_k.$$
    
    \item \textit{Geometric Distribution.}
    
    Let $p\in(0,1]$ and $X:\Omega\to\mathbb{N}_0$ be such that for each $n\in\mathbb{N}_0$,
    $$\textbf{P}[X=n]=p(1-p)^n.$$
    Then $\textbf{P}_X$ is called the \textit{geometric distribution with parameter $p$} and is denoted $\gamma_p$ or $b_{1,p}^{-}$. More formally,
    $$\gamma_p=\sum_{n=0}^\infty p(1-p)^n\delta_n.$$
    
    \item \textit{Negative Binomial Distribution.}
    
    Let $r>0$ and $p\in(0,1]$. We denote by
    $$b^{-}_{r,p}=\sum_{k=0}^\infty \binom{-r}{k}(-1)^kp^r(1-p)^k\delta_k$$
    the \textit{negative binomial distribution} or \textit{Pascal distribution} with parameters $r$ and $p$. Note that $r$ need not be an integer.
    
    \item \textit{Poisson Distribution.}
    
    Let $\lambda\in[0,\infty)$ and $X:\Omega\to\mathbb{N}_0$ be such that for each $n\in\mathbb{N}_0$,
    $$P[X=n]=e^{-\lambda}\frac{\lambda^n}{n!}.$$
    Then $\textbf{P}_x=\Poi_\lambda$ is called the \textit{Poisson distribution with parameter $\lambda$}.
    
    \item \textit{Hypergeoemetric Distribution.}
    
    Consider a basket with $B\in\mathbb{N}$ black balls and $W\in\mathbb{N}$ white balls. If we draw $n\in\mathbb{N}$ balls from the basket, some simple combinatorics shows that the probability of drawing (exactly) $b\in\{0,1,2,\ldots,n\}$ black balls is given by the \textit{hypergeometric distribution with parameters $B,W,n$}:
    $$\operatorname{Hyp}_{B,W;n}(\{b\})=\frac{\binom{B}{b}\binom{W}{n-b}}{\binom{B+W}{n}}.$$
    In general, if we have $k$ colors with $B_i$ balls of colour $i$ for each $i$, the probability of drawing exactly $b_i$ balls of colour $i$ for each $i$ is given by the \textit{generalised hypergeometric distribution}:
    $$\operatorname{Hyp}_{B_1,B_2,\ldots,B_k;n}(\left\{(b_1,b_2,\ldots,b_k)\right\}) = \frac{\binom{B_1}{b_1}\binom{B_2}{b_2}\cdots\binom{B_k}{b_k}}{\binom{B_1+B_2+\cdots+B_k}{n}}$$
    where $n=b_1+b_2+\cdots+b_k$.
    
    \item \textit{Gaussian Normal Distribution.}
    
    Let $\mu\in\mathbb{R}, \sigma^2>0$. Let $X$ be a real random variable such that for $x\in\mathbb{R}$,
    $$\textbf{P}[X\leq x]=\frac{1}{\sqrt{2\pi\sigma^2}}\int_{-\infty}^x \exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\d{t}$$
    Then $\textbf{P}_X$ is called the \textit{Gaussian normal distribution} (or just \textit{normal distribution}) \textit{with parameters $\mu$ and $\sigma^2$} and is denoted $\mathcal{N}_{\mu,\sigma^2}$. In particular, $\mathcal{N}_{0,1}$ is the standard normal distribution. 
    
    \item \textit{Exponential Distribution.}
    
    Let $\theta>0$ and $X$ be a nonnegative random variable such that for each $x\geq 0$,
    $$\textbf{P}[X\leq x]=\textbf{P}\left[X\in[0,x]\right]=\int_{0}^x\theta e^{-\theta t}\d{t}.$$
    Then $\textbf{P}_X$ is called the \textit{exponential distribution with parameter $\theta$} and is denoted $\exp_\theta$.
    
    % \item \textit{$d$-dimensional Normal Distribution.}
    
    % Let $\mu\in\mathbb{R}^d$ and $\Sigma$ be a positive definite symmetric $d\times d$ matrix. Let $X$ be an $\mathbb{R}^d$-valued random variable such that for each $x\in\mathbb{R}^d$,
    % $$\textbf{P}[X\leq x] = \det(2\pi\Sigma)^{-1/2}\int_{-\infty}^x \exp\left(-\frac{1}{2}\langle t-\mu, \Sigma^{-1}(t-\mu)\rangle\right)\lambda^d\d{t}$$
    % where $\langle\cdot,\cdot\rangle$ represents the standard inner product in $\mathbb{R}^d$. Then $\textbf{P}_X$ is called the \textit{$d$-dimensional normal distribution with parameters $\mu$ and $\Sigma$} and is denoted $\mathcal{N}_{\mu,\Sigma}$.
    
\end{enumerate}

\subsection{The Product Measure}

Let $E$ be a finite set and $\Omega=E^\mathbb{N}$. Let $(p_e)_{e\in E}$ be a probability vector. Define
$$\mathcal{A}=\{[\omega_1,\ldots,\omega_n]:\omega_1,\ldots,\omega_n\text{ and }n\in\mathbb{N}\}$$
and a content $\mu$ on $\mathcal{A}$ by
$$\mu([\omega_1,\omega_2,\ldots,\omega_n])=\prod_{i=1}^n p_{\omega_i}$$
We wish to extend $\mu$ to a measure on $\sigma(\mathcal{A})$. Similar to how we proved the existence of the Lebesgue-Stieltjes measure \ref{defLebStielMeasure}, we use a compactness argument to show that $\mu$ is $\sigma$-subadditive.

Let $A,A_1,A_2,\ldots\in\mathcal{A}$ such that $A\subseteq\bigcup_{i=1}^\infty A_i$. We claim that there exists $n\in\mathbb{N}$ such that $A\subseteq\bigcup_{i=1}^n A_i.$

For each $n\in\mathbb{N}$, let $B_n=A\setminus\bigcup_{i=1}^n A_i$. We assume that $B_n\neq\emptyset$ for all $n\in\mathbb{N}$ and prove the required by contradiction.

Due to the pigeonhole principle, there exists some $\omega_1\in E$ such that $[\omega_1]\cap B_n\neq\emptyset$ for infinitely many $n\in\mathbb{N}$. Since $B_1\supseteq B_2\supseteq\cdots$, we have that
$$[\omega_1]\cap B_n\neq\emptyset\text{ for all }n\in\mathbb{N}.$$
Similarly, there exist $\omega_2,\omega_3,\ldots\in E$ such that
$$[\omega_1,\ldots,\omega_k]\cap B_n\neq\emptyset\text{ for all }k,n\in\mathbb{N}.$$

Each $B_n$ is a disjoint union of sets $C_{n,1},\ldots,C_{n,m_n}\in\mathcal{A}$. Thus for each $n\in\mathbb{N}$, there is some $i_n\in\{1,2,\ldots,m_n\}$ such that
$$[\omega_1,\omega_2,\ldots,\omega_k]\cap C_{n,i_n}\neq\emptyset\text{ for infinitely many }k\in\mathbb{N}.$$
As $[\omega_1]\supseteq[\omega_1,\omega_2]\supseteq\cdots$, this implies that
$$[\omega_1,\omega_2,\ldots,\omega_k]\cap C_{n,i_n}\neq\emptyset\text{ for all } k\in\mathbb{N}$$

As $C_{n,i_n}\in\mathcal{A}$, for fixed $n$ and large $k$ ($k\geq m_n$), we have $$[\omega_1,\omega_2,\ldots,\omega_k]\subseteq C_{n,i_n}.$$
This implies that $\omega=(\omega_1,\omega_2,\ldots)\in C_{n,i_n}\subseteq B_n$. This in turn implies that $\bigcap_{i=0}^\infty B_i\neq\emptyset$, which yields a contradiction.

Therefore, $A\subseteq\bigcup_{i=1}^n A_n$ for some $n\in\mathbb{N}$. Since $\mu$ is known to be (finite) subadditive, we have
$$\mu(A)\leq \sum_{i=1}^n\mu(A_i)\leq \sum_{i=1}^\infty \mu(A_i),$$
which is the required result.

\begin{definition}[Product Measure]
\label{defProductMeasure}
    Let $E$ be a finite nonempty set and $\Omega=E^\mathbb{N}$. Let $(p_e)_{e\in E}$ be a probability vector. There then is a unique probability measure $\mu$ on $\sigma(\mathcal{A})=\mathcal{B}(\Omega)$ (where $\mathcal{A}$ is defined as above) such that
    $$\mu([\omega_1,\omega_2,\ldots,\omega_n])=\prod_{i=1}^n p_{\omega_i}\text{ for all $\omega_i\in E$ and $n\in\mathbb{N}$}.$$
    $\mu$ is called the \textit{product measure} or \textit{Bernoulli measure} on $\Omega$ with weights $(p_e)_{e\in E}$ and is denoted by $\left(\sum_{e\in E}p_e\delta_e\right)^{\otimes\mathbb{N}}$. The $\sigma$-algebra $\sigma(\mathcal{A})$ is called the \textit{product $\sigma$-algebra on $\Omega$} and is denoted by $(2^E)^{\otimes\mathbb{N}}$.
\end{definition}

We explain the above more intuitively in the following subsection.

\subsection{Independent Events}

In the following, let $(\Omega,\mathcal{A},\textbf{P})$ be a probability space and the sets $A\in\mathcal{A}$ be events. The $\Pr$ or $\textbf{P}$ symbol will denote the universal object of a probability measure (we used $\textbf{P}$ to denote this until now), and the probabilities $\Pr[\cdot]$ are always written in (square) brackets.
    
\begin{definition}
    Two events $A$ and $B$ are said to be \textit{independent} if
    $$\Pr[A\cap B] = \Pr[A]\Pr[B].$$
\end{definition}

An common example of independent events is that of rolling a die twice, where the outcome of the first roll is independent of the second.

Here, $\Omega=\{1,2,\ldots,6\}^2, \mathcal{A}=2^\Omega$ and the probability distribution is $\textbf{P}=\mathcal{U}_\Omega$. Our claim may be verified as follows. Let $\tilde A,\tilde B\subseteq\Omega, A=\tilde A\times\Omega$ and $B=\Omega\times\tilde B$. We must show that $\Pr[A]\Pr[B]=\Pr[A\cap B]$. This is obvious as follows:
\begin{align*}
    \Pr[A] &= \frac{|A|}{36}=\frac{|\tilde A|}{6} \\
    \Pr[B] &= \frac{|B|}{36}=\frac{|\tilde B|}{6} \\
    \Pr[A\cap B] &= \frac{|A\cap B|}{36} = \frac{|\tilde A||\tilde B|}{36} = \Pr[A]\Pr[B].
\end{align*}

While in the above example it is intuitively clear that the two events must be independent, we can have less obvious examples as well. For example, the event that the sum of the two rolls is odd and the event that the first roll gives at most a three are independent. We leave it to the reader to verify this claim.

\vspace{2mm}
We extend this definition of two independent events to any number of independent events as follows.

\begin{definition}[Independence of Events]
    Let $I$ be an index set and $(A_i)_{i\in I}$ be a family of events. The family $(A_i)_{i\in I}$ is called \textit{independent} if for any finite subset $J\subseteq I$, the following holds:
    $$\Pr\left[\bigcap_{j\in J}A_j\right]=\prod_{j\in J}\Pr[A_j].$$
\end{definition}

Let us now return to the product measure discussed in \ref{defProductMeasure}, which can be understood intuitively as follows. If $E$ is a finite set of outcomes, consider the probability space comprising $\Omega=E^\mathbb{N}$, the $\sigma$-algebra
$$\mathcal{A}=\sigma([\omega_1,\ldots,\omega_n]:\omega_1,\ldots,\omega_n\in E\text{ and }n\in\mathbb{N})$$
and the product measure $\textbf{P}=\left(\sum_{e\in E}p_e\delta_e\right)^{\otimes\mathbb{N}}$. This basically represents that we repeatedly conduct the experiment of choosing an outcome from $E$. Let $\tilde A_i\subseteq E$ for any $i\in\mathbb{N}$ and let $A_i$ be the event such that $\tilde A_i$ occurs in the $i$th experiment, given by
$$A_i = \{\omega\in\Omega:\omega_i\in\tilde A_i\}
  =\biguplus_{(\omega_1,\ldots,\omega_i)\in E^{i-1}\times \tilde A_i} [\omega_1,\ldots,\omega_i]$$

Intuitively, the family $(A_i)_{i\in\mathbb{N}}$ should be independent, since the outcome of one of the conducted experiments does not depend on the outcomes of the other experiments.

Let us check this. Let $J\subseteq\mathbb{N}$. For $j\in J$, let $B_j=A_j$ and $\tilde B_j=\tilde A_j$ and for $j\in\{1,2,\ldots,n\}\setminus J$, let $B_j=\Omega$ and $\tilde B_j=E$. Then
\begin{align*}
    \Pr\left[\bigcap_{j\in J}A_j\right] &= \Pr\left[\bigcap_{j=1}^n B_j\right] \\
    &= \Pr\left[\left\{\omega\in\Omega:\omega_j\in\tilde B_j\text{ for each }j\in\{1,2,\ldots,n\}\right\}\right] \\
    &= \sum_{e_1\in\tilde B_1} \cdots \sum_{e_n\in\tilde B_n} \prod_{j=1}^n p_{e_j} \\
    &= \prod_{j=1}^n \left(\sum_{e\in\tilde B_j}p_e\right) \\
    &= \prod_{j\in J} \left(\sum_{e\in\tilde A_j}p_e\right)
\end{align*}

As this is true in particular for $|J|=1$, we have for some fixed $i\in\{1,2,\ldots,n\}$,
$$\Pr[A_i] = \left(\sum_{e\in\tilde A_i}p_e\right).$$
Substituting the above, we have
$$
\Pr\left[\bigcap_{j\in J}A_j\right] 
= \prod_{j\in J} \left(\sum_{e\in\tilde A_j}p_e\right)
= \prod_{j\in J} \Pr[A_j].
$$
This proves the result.

\vspace{2mm}
Note that if events $A$ and $B$ are independent, then the events $A^c$ and $B$ are independent as well. This can be described more precisely as follows.

\begin{theorem}
    Let $I$ be an index set and $(A_i)_{i\in I}$ be a family of events. Define $B_i^0 = A_i$ and $B_i^1 = A_i^c$ for each $i\in I$. Then the following statements are equivalent.
    \begin{enumerate}[(a)]
        \item The family $(A_i)_{i\in I}$ is independent.
        \item There is some $\alpha\in\{0,1\}^I$ such that the family $(B_i^{\alpha_i})_{i\in I}$ is independent.
        \item For all $\alpha\in\{0,1\}^I$, the family $(B_i^{\alpha_i})_{i\in I}$ is independent.
    \end{enumerate}
\end{theorem}

We leave the proof of the above to the reader.

Now, recall the limes superior, defined in \ref{defLimes}. The limes superior represents the event that a particular event occurs an infinite amount of times. For example, if we roll a die an infinite number of times, we could consider the event that we roll a four an infinite number of times. This is formalized in the following.

\begin{theorem}[Borel-Cantelli Lemma]
\label{borelCantelliLemma}
    Let $A_1,A_2,\ldots$ be events and define $A^*=\limsup_{n\to\infty} A_n$. Then
    \begin{enumerate}[(a)]
        \item If $\sum_{n=1}^\infty \Pr[A_n]<\infty$, $\Pr[A^*]=0$.
        \item If $(A_n)_{n\in\mathbb{N}}$ is independent and $\sum_{n=1}^\infty \Pr[A_n]=\infty$, then $\Pr[A^*]=1$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    By \ref{tripledoubleEquivalence}, $\textbf{P}$ is upper semicontinuous, lower semicontinuous and $\sigma$-subadditive.
    \begin{enumerate}
        \item As $\textbf{P}$ is upper semicontinuous and $\sigma$-subadditive,
        \begin{align*}
            \Pr[A^*] &= \lim_{n\to\infty}\Pr\left[\bigcup_{m=n}^\infty A_m\right] \\
            &\leq \lim_{n\to\infty} \Pr[A_m] = 0
        \end{align*}
        The result follows.
        
        \item As $\textbf{P}$ is lower semicontinuous and the family $(A_n)_{n\in\mathbb{N}}$ is independent, we have
        \begin{align*}
            \Pr[(A^*)^c] &= \Pr\left[\bigcup_{n=1}^\infty\bigcap_{m=n}^\infty A_m^c\right] \\
            &= \lim_{n\to\infty} \Pr\left[\bigcap_{m=n}^\infty A_m^c\right] \\
            &= \lim_{n\to\infty} \prod_{m=n}^\infty \left(1-\Pr[A_m]\right) \\
        \end{align*}
        Now for any $n\in\mathbb{N}$, as $\log(1-x)\leq -x$
        \begin{align*}
            \prod_{m=n}^\infty \left(1-\Pr[A_m]\right)&= \exp\left(\sum_{m=n}^\infty \log(1-\Pr[A_m])\right) \\
            &\leq \exp\left(-\sum_{m=n}^\infty \Pr[A_m]\right) = 0
        \end{align*}
        The result follows.
    \end{enumerate}
\end{proof}

The reader may verify using the Borel-Cantelli Lemma that if we roll a die an infinite number of times, the probability of rolling a four an infinite number of times is $1$ by considering the events $A_n = \{\omega\in\Omega:\omega_n=6\}$ for each $n\in\mathbb{N}$ where $\Omega=\{1,\ldots,6\}^\mathbb{N}$.

\vspace{2mm}
We now extend the definition of independence of a family of events as follows.

\begin{definition}[Independence of classes of events]
\label{independence of classes of events}
    Let $I$ be an index set and $\mathcal{E}_i\subseteq\mathcal{A}$ for all $i\in I$. The family $(\mathcal{E}_i)_{i\in I}$ is called \textit{independent} if for any finite $J\subseteq I$ and any choice of $E_j\in\mathcal{E}_j$ and $j\in J$, the family $(E_j)_{j\in J}$ is independent.
\end{definition}

For example, if we roll a die an infinite number of times, for each $i\in\mathbb{N}$, consider the class of events given by $\mathcal{E}_i=\{\{\omega\in\Omega:\omega_i\in A\}:A\subseteq\{1,\ldots,6\}\}$
where $\Omega=\{1,\ldots,6\}^\mathbb{N}$. Then the family $(\mathcal{E}_i)_{i\in I}$ is independent.

\begin{theorem}
~
    Let $I$ be an index set and for each $i\in I$, let $\mathcal{E}_i\subseteq \mathcal{A}$. Then
    \begin{enumerate}[(a)]
        \item Let $I$ be finite. If $\Omega\in\mathcal{E}_i$ for each $i$, then $(\mathcal{E}_i)_{i\in I}$ is independent if and only if $(E_i)_{i\in I}$ is independent for any choice of $E_i\in\mathcal{E}_i,i\in I$.
        
        \item If $(\mathcal{E}_i\cup\{\emptyset\})$ is $\cap$-closed for each $i$, then $(\mathcal{E}_i)_{i\in I}$ is independent if and only if $(\sigma(\mathcal{E}_i))_{i\in I}$ is independent.
        
        % \item Let $K$ be an arbitrary set and let $(I_k)_{k\in K}$ be mutually disjoint subsets of $I$. If $(\mathcal{E}_i)_{i\in I}$ is independent, then $\left(\bigcup_{i\in I_k}\mathcal{E}_i\right)_{k\in K}$ is also independent.
    \end{enumerate}
\end{theorem}

\begin{proof}
    ~
    \begin{enumerate}[(a)]
        \item The forward implication is obvious from the definition. To prove the backward implication, for $J\subseteq I$ and $j\in I\setminus J$, choose $E_j=\Omega$.
        
        \item The backward implication is obvious. Let us now prove the forward implication.
        
        First, we claim that for any $J\subseteq J'\subseteq I$ where $J$ is finite, 
        $$\Pr\left[\bigcap_{i\in J'}E_i\right] = \prod_{i\in J'}\Pr[E_i]$$
        for any choice of $E_i\in\sigma(\mathcal{E}_i)$ if $i\in J$ and
        $E_i\in\mathcal{E}_i$ if $i\in J'\setminus J$.
        
        We shall prove the above claim by induction on $|J|$. If $|J|=0$, then the claim is true as $(\mathcal{E}_i)_{i\in I}$ is independent. Now assume that the claim is true for all $J\subseteq I$ with $|J|=n$ and all finite $J'\supseteq J$. Fix such a $J$. Let $j\in I\setminus J$. Define $\tilde J=J\cup\{j\}$ and choose some $J'\supseteq\tilde J$. We shall show that the claim is true if we replace $J$ with $\tilde J$, thus proving the inductive step.
    
        Fix $E_i\in\sigma(\mathcal{E}_i)$ for each $i\in J$ and $E_i\in\mathcal{E}_i$ for each $i\in J'\setminus\tilde J$. Consider measures $\mu,\nu$ on $(\Omega,\mathcal{A})$ such that
        \begin{align*}
            \mu &: E_j\mapsto \Pr\left[\bigcap_{i\in J'}E_i\right] \\
            \nu &: E_j\mapsto \prod_{i\in J'}\Pr[E_i]
        \end{align*}
        By the induction hypothesis, $\mu(E_j)=\nu(E_j)$ for all $E_j\in\mathcal{E}_j\cup\{\emptyset,\Omega\}$. As $\mathcal{E}_j\cup\{\emptyset\}$ is $\cap$-closed, \ref{uniquely defined by base pi sys} implies that $\mu(E_j)=\nu(E_j)$ for all $E_j\in\sigma(\mathcal{E}_j)$.
        
        This proves our claim. Setting $J=J'$ yields the required result.
    
    \end{enumerate}
\end{proof}
